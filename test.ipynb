{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600944266969",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import kernel\n",
    "y1, y2 = np.random.binomial(1, 0.5, (250,)), np.random.binomial(1, 0.75, (100,))\n",
    "x1, x2 = np.random.normal(loc = y1 * 1.5, scale= 1, size=(250,)), np.random.normal(loc = y2 * 1, scale= 1.5, size=(100,))\n",
    "x1, x2 = np.reshape(x1, (250, 1)), x2.reshape((100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.271 0.729]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True])"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Unlabeled classifier; lipton\n",
    "import unsupervised\n",
    "n, d = np.shape(x1)\n",
    "beta, kernel_df = 5, 5\n",
    "cl4 = unsupervised.WithoutLabelClassifier(kernel_df=kernel_df, beta=beta)\n",
    "cl4.fit(x1, y1, x2, method='lipton')\n",
    "y2 == cl4.predict(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "cl4 = classifier.KDEClassifier(kernel_df=kernel_df, bandwidth=bandwidth)\n",
    "prop_target = 0.75\n",
    "cl4.fit(x1, y1, [1-prop_target, prop_target])\n",
    "cl3.predict(x2) == y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 25 * (2 ** np.linspace(0, 9, 10))\n",
    "b = np.repeat(100, 10)\n",
    "c = np.array([10, 20, 40, 80, 160, 320, 640, 1280, 2560, 5120])\n",
    "e1 = np.column_stack((a, b))\n",
    "e2 = np.column_stack((b/2, c))\n",
    "sample_sizes1 = np.vstack((e1, e2))\n",
    "label1 = np.repeat(False, 10)\n",
    "\n",
    "a = 25 * (2 ** np.linspace(3, 9, 7))\n",
    "b = np.repeat(50, 7)\n",
    "e1 = np.column_stack((a-b, b))\n",
    "e2 = np.column_stack((b, a-b))\n",
    "sample_sizes2 = np.vstack((e1, e2))\n",
    "label2 = np.repeat(True, 7)\n",
    "\n",
    "sample_sizes = np.vstack((sample_sizes1, sample_sizes2))\n",
    "sample_sizes = np.array(sample_sizes, dtype = 'int32')\n",
    "label = np.array([False] * 20 + [True] * 14, dtype='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sample_sizes.npy', sample_sizes)\n",
    "np.save('label.npy', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[   25,   100],\n       [   50,   100],\n       [  100,   100],\n       [  200,   100],\n       [  400,   100],\n       [  800,   100],\n       [ 1600,   100],\n       [ 3200,   100],\n       [ 6400,   100],\n       [12800,   100],\n       [   50,    10],\n       [   50,    20],\n       [   50,    40],\n       [   50,    80],\n       [   50,   160],\n       [   50,   320],\n       [   50,   640],\n       [   50,  1280],\n       [   50,  2560],\n       [   50,  5120],\n       [  150,    50],\n       [  350,    50],\n       [  750,    50],\n       [ 1550,    50],\n       [ 3150,    50],\n       [ 6350,    50],\n       [12750,    50],\n       [   50,   150],\n       [   50,   350],\n       [   50,   750],\n       [   50,  1550],\n       [   50,  3150],\n       [   50,  6350],\n       [   50, 12750]], dtype=int32)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "sample_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True])"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.74, array([0.5       , 1.54166667]))"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import prop_estimation\n",
    "prop_estimation.lipton_method(x1, y1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.41 0.08]\n [0.05 0.46]]\n[[0.41 0.08]\n [0.05 0.46]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.17742145, 0.82257855])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "D = data.DataGenerator(d = 4)\n",
    "x_source, y_source = D.getData(100, 0.5, 2)\n",
    "x_target, y_target = D.getData(100, 0.75, 2)\n",
    "m, d = np.shape(x_source)\n",
    "prop_source = np.mean(y_source)\n",
    "\n",
    "cl = LogisticRegression(penalty='none')\n",
    "cl.fit(x_source, y_source)\n",
    "confusion_matrix = metrics.confusion_matrix(cl.predict(x_source),y_source)/m \n",
    "print(confusion_matrix)\n",
    "if np.prod(np.diag(confusion_matrix)) == 0:\n",
    "    confusion_matrix = confusion_matrix + 0.01 * np.identity(d)\n",
    "print(confusion_matrix)\n",
    "confusion_matrix = confusion_matrix/np.sum(confusion_matrix)\n",
    "prop_target = np.mean(cl.predict(x_target))\n",
    "    \n",
    "xi = np.array([1-prop_target,prop_target])\n",
    "w = np.matmul(np.linalg.inv(confusion_matrix),xi)\n",
    "prop_targets = w*np.array([1-prop_source, prop_source])\n",
    "prop_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1.53061224, 0.51020408])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "np.matmul(np.linalg.inv(confusion_matrix), xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1.10036881, 0.90279241])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "11"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "w * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.41"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "prop_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.53531976, 0.4644503 ])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "prop_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.95592814, 1.05556886])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "np.sum(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.08639999999999999"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "np.prod(np.diag(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "70"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "np.sum(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}